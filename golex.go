package main

import (
	"bytes"
	"errors"
	"fmt"
	"io"
	"os"
	"regexp"
	"strings"
	"text/template"

	"golang.org/x/tools/imports"
)

// Embedded
// RegexPatterns
// Matchers
const tmpl = `// Code generated by golex DO NOT EDIT.

package lex

import (
	"errors"
	"io"
	"regexp"
)

{{ .Embedded }}

var yytext string

const (
{{ .RegexPatterns }}
)

type Lexer struct {
	data string
	pos  int
}

func NewLexer(data string) *Lexer {
	return &Lexer{
		data: data,
		pos:  0,
	}
}

func (lex *Lexer) NextToken() (ReturnType, error) {
	for {
		prevPos := lex.pos
		if lex.pos >= len(lex.data) {
			return ReturnType{}, io.EOF
		}
		if !lex.match(regPatterns) {
			break
		}

		{{ .Matchers }}

		if prevPos == lex.pos {
			return ReturnType{}, errors.New("infinite loop")
		}
	}

	return ReturnType{}, errors.New("no match")
}

func (lex *Lexer) match(expr string) bool {
	re := regexp.MustCompile(expr)
	re.Longest()
	yytext = re.FindString(lex.data[lex.pos:])
	lex.pos += len(yytext)

	return yytext != ""
}`

func main() {
	// data, _ := os.ReadFile("/home/arch/workspace/github/golex/test.l")
	// Read config file
	if len(os.Args) != 3 {
		fmt.Println("Usage: golex <lexer config> <generated filename>\n       golex /path/to/sample.l /path/to/output_gen.go")
		return
	}
	data, _ := os.ReadFile(os.Args[1])
	lexConfig := string(data)

	const embeddedRegex = `((?s)(\n{%\n(.*)\n%}|^{%\n(.*)\n%}))`
	ere := regexp.MustCompile(embeddedRegex)
	embedded := ere.FindStringSubmatch(lexConfig)
	if len(embedded) == 0 {
		panic("You must define type alias of ReturnType")
	}
	var embeddedBody string
	if embedded[len(embedded)-1] == "" {
		embeddedBody = embedded[len(embedded)-2]
	} else {
		embeddedBody = embedded[len(embedded)-1]
	}

	const regPattRegex = `(?s)\n%%\n(.*)\n%%`
	rre := regexp.MustCompile(regPattRegex)
	regPatts := rre.FindStringSubmatch(lexConfig)
	if len(regPatts) == 0 {
		panic("regex pattern is required")
	}

	regLexer := NewRegexLexer(regPatts[1])
	tokens := regLexer.lex()
	regexPatterns := makeRegexPatterns(tokens)
	matchers := makeMachers(tokens)

	lexCfg := LexerTemplate{
		Embedded:      embeddedBody,
		RegexPatterns: regexPatterns,
		Matchers:      matchers,
	}
	s := tmpl
	t := template.Must(template.New("lexer").Parse(s))

	var buf bytes.Buffer
	filename := os.Args[2]
	if err := t.Execute(&buf, lexCfg); err != nil {
		panic(err)
	}
	// t.Execute(os.Stdout, lexCfg)
	data, err := imports.Process(filename, buf.Bytes(), nil)
	if err != nil {
		panic(err)
	}
	err = os.WriteFile(filename, data, 0644)
	if err != nil {
		panic(err)
	}
}

func makeRegexPatterns(tokens []RegexAction) string {
	n := len(tokens)
	patts := []string{}
	for i := 0; i < n; i++ {
		patts = append(patts, fmt.Sprintf("regPattern%v", i))
	}

	ret := make([]byte, 0)
	for i, tok := range tokens {
		ret = append(ret, []byte(fmt.Sprintf("regPattern%v = \"^%v\"\n", i, tok.pattern))...)
	}

	return fmt.Sprintf("regPatterns = %v\n%v", strings.Join(patts, " + \"|\" + "), string(ret))
}

func makeMachers(tokens []RegexAction) string {
	ms := make([]byte, 0)
	for i, tok := range tokens {
		s := fmt.Sprintf("if matched, _ := regexp.MatchString(regPattern%v+\"$\", yytext); matched {\n%v\ncontinue\n}\n", i, tok.body)
		ms = append(ms, []byte(s)...)
	}

	return string(ms)
}

type RegexLexer struct {
	body string
	pos  int
	len  int
}

type RegexAction struct {
	pattern string
	body    string
}

func NewRegexLexer(regBody string) *RegexLexer {
	return &RegexLexer{
		body: regBody,
		pos:  0,
		len:  len(regBody),
	}
}

func (lex *RegexLexer) lex() []RegexAction {
	regexs := make([]RegexAction, 0)
	for {
		reg, err := lex.nextToken()
		if err != nil {
			if errors.Is(err, io.EOF) {
				return regexs
			}
		}
		body, err := lex.nextToken()
		if err != nil {
			if errors.Is(err, io.EOF) {
				return regexs
			}
		}
		regexs = append(regexs, RegexAction{pattern: reg, body: body})
	}
}

func (lex *RegexLexer) skipWhitespace() {
	if lex.pos >= lex.len {
		return
	}
	for {
		switch lex.peek() {
		case ' ', '\n', '\t', '\r':
			lex.next()
			continue
		default:
			return
		}
	}
}

func (lex *RegexLexer) nextToken() (string, error) {
	lex.skipWhitespace()
	if lex.pos >= lex.len {
		return "", io.EOF
	}
	switch lex.peek() {
	case '"':
		return lex.readRegexPattern(), nil
	case '{':
		return lex.readBody(), nil
	}

	panic(errors.New("lexer error"))
}

func (lex *RegexLexer) readRegexPattern() string {
	s := make([]byte, 0)
	lex.next()
	var prev byte
	for {
		if lex.peek() == '"' {
			if prev == '\\' {
				s = append(s, '"')
			} else {
				break
			}
		} else {
			s = append(s, lex.peek())
		}
		prev = lex.peek()
		lex.next()
	}
	lex.next()

	return string(s)
}

func (lex *RegexLexer) readBody() string {
	lex.skipWhitespace()
	s := []byte{'{'}
	lex.next()
	stack := []struct{}{{}}
	for {
		if lex.peek() == '}' {
			if len(stack) == 1 {
				break
			}
			stack = stack[0 : len(stack)-1]
		}
		if lex.peek() == '{' {
			stack = append(stack, struct{}{})
		}
		s = append(s, lex.peek())
		lex.next()
	}
	s = append(s, '}')
	lex.next()

	return string(s)
}

func (lex *RegexLexer) peek() byte {
	return lex.body[lex.pos]
}

func (lex *RegexLexer) next() {
	lex.pos++
}

type LexerTemplate struct {
	Embedded      string
	RegexPatterns string
	Matchers      string
}
